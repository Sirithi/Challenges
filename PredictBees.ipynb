{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f544fe6f-86fc-4696-8007-0f91d9758d69",
   "metadata": {},
   "source": [
    "# Predict bee image health"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c295588b-1e95-4eec-90a3-ddebdaf034d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the dataset as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386ac96d-584c-469a-828e-b9a0473eae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90b2f13-f243-4643-bae9-0d352d27b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          file     date   time        location  zip code subspecies  \\\n",
      "0  041_066.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "1  041_072.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "2  041_073.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "3  041_067.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "4  041_059.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "\n",
      "              health  pollen_carrying   caste  \n",
      "0  hive being robbed            False  worker  \n",
      "1  hive being robbed            False  worker  \n",
      "2  hive being robbed            False  worker  \n",
      "3  hive being robbed            False  worker  \n",
      "4  hive being robbed            False  worker  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('bee_data.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0786ff-cd27-40fe-b98f-3112b9b3236d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now we create a path column to out dataframe\n",
    "\n",
    "In this column we will append the directory path to the image from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9121a4fb-a565-4f6d-9ea0-851c25551a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = \"./bee_imgs/bee_imgs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9444e26-c650-4724-9827-dff5fd286345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    fileName = row['file']\n",
    "    df.loc[index,'path'] = imgPath+str(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001b79d0-aab2-45f8-9c6e-ae176a43b210",
   "metadata": {},
   "source": [
    "Check if the new column named path has the correct path to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e151810a-0ba5-4775-b369-dedec61fb19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          file     date   time        location  zip code subspecies  \\\n",
      "0  041_066.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "1  041_072.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "2  041_073.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "3  041_067.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "4  041_059.png  8/28/18  16:07  Alvin, TX, USA     77511         -1   \n",
      "\n",
      "              health  pollen_carrying   caste                             path  \n",
      "0  hive being robbed            False  worker  ./bee_imgs/bee_imgs/041_066.png  \n",
      "1  hive being robbed            False  worker  ./bee_imgs/bee_imgs/041_072.png  \n",
      "2  hive being robbed            False  worker  ./bee_imgs/bee_imgs/041_073.png  \n",
      "3  hive being robbed            False  worker  ./bee_imgs/bee_imgs/041_067.png  \n",
      "4  hive being robbed            False  worker  ./bee_imgs/bee_imgs/041_059.png  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d88c5d5-1725-4cc2-811e-c54d49e73985",
   "metadata": {},
   "source": [
    "## Split the values in train validate and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab864c07-c01c-4d99-a844-a640ea213dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44670612-387b-4b08-a8ae-f8755ef00689",
   "metadata": {},
   "source": [
    "### We will split the data in three parts\n",
    "\n",
    "These parts are going to be train, validate and test. We will use train to make the models, validate to choose the best one and test to see how good it really is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c038ec-57c5-4adb-9112-aaf010a39d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(df['health'])\n",
    "df['facCat'] = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a89a4776-f365-42e2-8573-ad07b5c01516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             file     date   time           location  zip code subspecies  \\\n",
      "0     041_066.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
      "1     041_072.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
      "2     041_073.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
      "3     041_067.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
      "4     041_059.png  8/28/18  16:07     Alvin, TX, USA     77511         -1   \n",
      "...           ...      ...    ...                ...       ...        ...   \n",
      "5167  027_011.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
      "5168  027_007.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
      "5169  027_013.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
      "5170  027_012.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
      "5171  027_014.png  8/20/18  10:03  San Jose, CA, USA     95124         -1   \n",
      "\n",
      "                 health  pollen_carrying   caste  \\\n",
      "0     hive being robbed            False  worker   \n",
      "1     hive being robbed            False  worker   \n",
      "2     hive being robbed            False  worker   \n",
      "3     hive being robbed            False  worker   \n",
      "4     hive being robbed            False  worker   \n",
      "...                 ...              ...     ...   \n",
      "5167            healthy             True  worker   \n",
      "5168            healthy             True  worker   \n",
      "5169            healthy            False  worker   \n",
      "5170            healthy            False  worker   \n",
      "5171            healthy            False  worker   \n",
      "\n",
      "                                 path  facCat  \n",
      "0     ./bee_imgs/bee_imgs/041_066.png       0  \n",
      "1     ./bee_imgs/bee_imgs/041_072.png       0  \n",
      "2     ./bee_imgs/bee_imgs/041_073.png       0  \n",
      "3     ./bee_imgs/bee_imgs/041_067.png       0  \n",
      "4     ./bee_imgs/bee_imgs/041_059.png       0  \n",
      "...                               ...     ...  \n",
      "5167  ./bee_imgs/bee_imgs/027_011.png       1  \n",
      "5168  ./bee_imgs/bee_imgs/027_007.png       1  \n",
      "5169  ./bee_imgs/bee_imgs/027_013.png       1  \n",
      "5170  ./bee_imgs/bee_imgs/027_012.png       1  \n",
      "5171  ./bee_imgs/bee_imgs/027_014.png       1  \n",
      "\n",
      "[5172 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883e8ea8-98cf-487b-a3f2-6f64f89d20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tv, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['facCat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53dcbac7-fbe1-4e8c-8060-3586825b731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_tv, test_size=0.2, random_state=42, stratify=df_tv['facCat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cae85b5-4177-4c2d-b411-1a7766e4c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrames = [\"df_test\", \"df_train\", \"df_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cb5fc90-4300-4bd8-a557-a0d19d88802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              file     date   time              location  zip code  \\\n",
      "4405   038_094.png  8/18/18  12:30  Athens, Georgia, USA     30607   \n",
      "851    030_607.png  8/17/18  17:50        Alvin, TX, USA     77511   \n",
      "2977   010_854.png  8/19/18  12:46   Des Moines, IA, USA     50315   \n",
      "1132   030_726.png  8/17/18  17:50        Alvin, TX, USA     77511   \n",
      "4743  019_1355.png   8/6/18  19:19     Saratoga, CA, USA     95070   \n",
      "...            ...      ...    ...                   ...       ...   \n",
      "1857   040_487.png  8/21/18  15:56       Athens, GA, USA     30607   \n",
      "4865  019_1265.png   8/6/18  19:19     Saratoga, CA, USA     95070   \n",
      "4141   032_719.png  8/21/18   9:00   Des Moines, IA, USA     50315   \n",
      "4059   032_578.png  8/21/18   9:00   Des Moines, IA, USA     50315   \n",
      "4615   038_385.png  8/18/18  12:30  Athens, Georgia, USA     30607   \n",
      "\n",
      "                 subspecies                      health  pollen_carrying  \\\n",
      "4405  1 Mixed local stock 2  Varroa, Small Hive Beetles            False   \n",
      "851       Italian honey bee                ant problems            False   \n",
      "2977    Carniolan honey bee                     healthy            False   \n",
      "1132      Italian honey bee                ant problems            False   \n",
      "4743      Italian honey bee                     healthy            False   \n",
      "...                     ...                         ...              ...   \n",
      "1857      Italian honey bee    few varrao, hive beetles            False   \n",
      "4865      Italian honey bee                     healthy            False   \n",
      "4141      Russian honey bee                     healthy            False   \n",
      "4059      Russian honey bee                     healthy            False   \n",
      "4615  1 Mixed local stock 2  Varroa, Small Hive Beetles            False   \n",
      "\n",
      "       caste                              path  facCat  \n",
      "4405  worker   ./bee_imgs/bee_imgs/038_094.png       5  \n",
      "851   worker   ./bee_imgs/bee_imgs/030_607.png       3  \n",
      "2977  worker   ./bee_imgs/bee_imgs/010_854.png       1  \n",
      "1132  worker   ./bee_imgs/bee_imgs/030_726.png       3  \n",
      "4743  worker  ./bee_imgs/bee_imgs/019_1355.png       1  \n",
      "...      ...                               ...     ...  \n",
      "1857  worker   ./bee_imgs/bee_imgs/040_487.png       2  \n",
      "4865  worker  ./bee_imgs/bee_imgs/019_1265.png       1  \n",
      "4141  worker   ./bee_imgs/bee_imgs/032_719.png       1  \n",
      "4059  worker   ./bee_imgs/bee_imgs/032_578.png       1  \n",
      "4615  worker   ./bee_imgs/bee_imgs/038_385.png       5  \n",
      "\n",
      "[3309 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4915630-fa3c-4399-838e-85d73e484af3",
   "metadata": {},
   "source": [
    "### New dataframes\n",
    "\n",
    "We now have three dataframes, **df_test**, **df_train**, **df_val**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf21fd95-749f-486d-9024-5c14a6c0cb3c",
   "metadata": {},
   "source": [
    "### Factorize check\n",
    "\n",
    "Now we also want to know which factorize number equals what state of health. We are going to find that out next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e39d791-f406-4e64-8b69-b54feb77a51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hive being robbed' 'healthy' 'few varrao, hive beetles' 'ant problems'\n",
      " 'missing queen' 'Varroa, Small Hive Beetles']\n"
     ]
    }
   ],
   "source": [
    "uniqueHealths = pd.unique(df['health'])\n",
    "print(uniqueHealths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "892d4dd3-c994-478c-a4e0-366ff2032a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hive being robbed': 0, 'healthy': 1, 'few varrao, hive beetles': 2, 'ant problems': 3, 'missing queen': 4, 'Varroa, Small Hive Beetles': 5}\n"
     ]
    }
   ],
   "source": [
    "healthStates = {}\n",
    "\n",
    "df.reset_index()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    healthOfRow = row['health']\n",
    "    if healthOfRow not in healthStates:\n",
    "        healthStates[healthOfRow] = row['facCat']\n",
    "\n",
    "print(healthStates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e4020-67b2-41d0-ac8c-3f3cc3f564ff",
   "metadata": {},
   "source": [
    "### Start making out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e130e6-a70b-4a1c-a29f-22939d3675ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b2edd-4724-461f-a28b-42e3a7def73e",
   "metadata": {},
   "source": [
    "### We first need to load all the images from the **df_train**\n",
    "\n",
    "To do this we need to create a file structure where every dataframe is a file containing folders named after the health state and the images in the corresponding folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45713646-597a-484f-bb97-71ab7568055a",
   "metadata": {},
   "source": [
    "This is what we want to print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f226453-a8ae-4193-abbd-8ec1d670299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test\n",
      "   df_test/hive being robbed\n",
      "   df_test/healthy\n",
      "   df_test/few varrao, hive beetles\n",
      "   df_test/ant problems\n",
      "   df_test/missing queen\n",
      "   df_test/Varroa, Small Hive Beetles\n",
      "df_train\n",
      "   df_train/hive being robbed\n",
      "   df_train/healthy\n",
      "   df_train/few varrao, hive beetles\n",
      "   df_train/ant problems\n",
      "   df_train/missing queen\n",
      "   df_train/Varroa, Small Hive Beetles\n",
      "df_val\n",
      "   df_val/hive being robbed\n",
      "   df_val/healthy\n",
      "   df_val/few varrao, hive beetles\n",
      "   df_val/ant problems\n",
      "   df_val/missing queen\n",
      "   df_val/Varroa, Small Hive Beetles\n"
     ]
    }
   ],
   "source": [
    "for x in dataFrames:\n",
    "    print(x)\n",
    "    for y in healthStates:\n",
    "        print(\"   \" + x + '/' + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "667c3308-a164-4821-9da6-cd8abab7b161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health directory hive being robbed in df_test already exists\n",
      "health directory healthy in df_test already exists\n",
      "health directory few varrao, hive beetles in df_test already exists\n",
      "health directory ant problems in df_test already exists\n",
      "health directory missing queen in df_test already exists\n",
      "health directory Varroa, Small Hive Beetles in df_test already exists\n",
      "health directory hive being robbed in df_train already exists\n",
      "health directory healthy in df_train already exists\n",
      "health directory few varrao, hive beetles in df_train already exists\n",
      "health directory ant problems in df_train already exists\n",
      "health directory missing queen in df_train already exists\n",
      "health directory Varroa, Small Hive Beetles in df_train already exists\n",
      "health directory hive being robbed in df_val already exists\n",
      "health directory healthy in df_val already exists\n",
      "health directory few varrao, hive beetles in df_val already exists\n",
      "health directory ant problems in df_val already exists\n",
      "health directory missing queen in df_val already exists\n",
      "health directory Varroa, Small Hive Beetles in df_val already exists\n"
     ]
    }
   ],
   "source": [
    "for x in dataFrames:\n",
    "    if not os.path.exists(x):\n",
    "        try:\n",
    "            os.mkdir(x)\n",
    "        except FileExistsError:\n",
    "            print(\"df directory \" + x + \" already exists\")\n",
    "    for y in healthStates:\n",
    "        if not os.path.exists(y):\n",
    "            try:\n",
    "                os.mkdir(x + '/' + y)\n",
    "            except FileExistsError:\n",
    "                print(\"health directory \" + y + \" in \" + x + \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b39b1e-1060-448d-83d0-7f450517912a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
